{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Date: 01/01/2024\n",
    "- Author: Carlos Javier Navarro\n",
    "- Project: EarthCul\n",
    "\n",
    "### Code to calculate count in points, or lines or polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to eliminate duplicate geometries generated at the junction of the layers to avoid generating false counts.\n",
    "1) To do this, first polygonize the layers so that it is a single geometry type. In the case of points, a buffer of 10 meters is set\n",
    "2) Then stick only with the unique geometries.\n",
    "3) Count the geometries inside of grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\carlo\\Documents\\EarthCul\\OSM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\geopandas\\io\\file.py:612: UserWarning: You are attempting to write an empty DataFrame to file. For some drivers, this operation may fail.\n",
      "  _to_file_fiona(df, filename, driver, schema, crs, mode, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import polygonize\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "base_path = os.getcwd()\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(base_path, '../..'))\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "park = 'Aiguestortes'\n",
    "\n",
    "# Input and output folders\n",
    "input_folder = os.path.join(project_root, '1_Variable download', 'EarthCul OSM', park, 'definitive variables')\n",
    "\n",
    "output_folder = os.path.join(project_root, '2_Derived metrics', 'count', 'Poligons', park)\n",
    "\n",
    "def convert_to_polygon(geom):\n",
    "    if geom.geom_type == 'Point':\n",
    "        return Point(geom.x, geom.y).buffer(0.0001)\n",
    "    elif geom.geom_type == 'LineString':\n",
    "        polygons = list(polygonize([geom]))\n",
    "        if polygons: \n",
    "            return polygons[0]  \n",
    "        else:\n",
    "            return None  \n",
    "    else:\n",
    "        return geom\n",
    "\n",
    "\n",
    "# Iterate through all files in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith('.geojson'):  \n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        vector = gpd.read_file(file_path)\n",
    "        vector['geometry'] = vector['geometry'].apply(convert_to_polygon)    \n",
    "        output_file_path = os.path.join(output_folder, f\"{os.path.splitext(file_name)[0]}.geojson\")  \n",
    "        vector.to_file(output_file_path, driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) After polygonizing select unique values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed process.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "\n",
    "# Path of the folder containing the GeoJSON files\n",
    "\n",
    "input_folder = os.path.join(base_path, '2_Derived metrics/count/Poligons', park)\n",
    "output_folder = os.path.join(base_path, '2_Derived metrics/count/Poligons uniques', park)\n",
    "\n",
    "\n",
    "# Pattern to select all GeoJSON files in folder\n",
    "patron = '*.geojson'\n",
    "archivos_geojson = glob.glob(os.path.join(input_folder, patron))\n",
    "\n",
    "# Process each GeoJSON file\n",
    "for archivo_geojson in archivos_geojson:\n",
    "    # Load the file into a GeoDataFrame\n",
    "    gdf = gpd.read_file(archivo_geojson)\n",
    "    \n",
    "    # Remove duplicate geometries\n",
    "    gdf_sin_duplicados = gdf.drop_duplicates()\n",
    "    \n",
    "    # Build the output path in the new folder\n",
    "    out_name = os.path.basename(archivo_geojson)\n",
    "    out_path = os.path.join(output_folder, out_name)\n",
    "    \n",
    "    # Save the new GeoDataFrame to a new GeoJSON file\n",
    "    gdf_sin_duplicados.to_file(out_path, driver='GeoJSON')\n",
    "    \n",
    "    print(f\"Duplicate geometries removed in {archivo_geojson}. New file saved in {out_path}\")\n",
    "\n",
    "print(\"Completed process.\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As there are some layers that are lines, it is better to count them separately.\n",
    "These are\n",
    "- Rivers\n",
    "- Roads\n",
    "- bike_routes\n",
    "- hiking_trails\n",
    "- railway\n",
    "- streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files copied successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# Input and output directory\n",
    "source_directory = os.path.join(project_root, '2_Derived metrics/count/Poligons', park)\n",
    "destination_directory = os.path.join(project_root, '2_Derived metrics/count/Poligons uniques', park)\n",
    "\n",
    "# Terms to search for in file names\n",
    "search_terms = [\"rivers\", \"roads\", \"bike\", \"hiking\", \"railway\", \"streets\"]\n",
    "\n",
    "# Create the destination directory if it does not exist\n",
    "if not os.path.exists(destination_directory):\n",
    "    os.makedirs(destination_directory)\n",
    "\n",
    "# Get the list of files in the source directory\n",
    "files_in_source = glob.glob(os.path.join(source_directory, \"*.geojson\"))\n",
    "\n",
    "# Filter files based on terms\n",
    "files_to_move = [file for file in files_in_source if any(term in os.path.basename(file) for term in search_terms)]\n",
    "\n",
    "# Move the filtered files to the destination directory\n",
    "for file in files_to_move:\n",
    "    destination_file = os.path.join(destination_directory, os.path.basename(file))\n",
    "    \n",
    "    # Check if the file already exists in the destination directory\n",
    "    if os.path.exists(destination_file):\n",
    "        print(f\"Overwriting {os.path.basename(file)} in {destination_directory}\")\n",
    "        os.remove(destination_file)  # Remove the existing file\n",
    "    \n",
    "    # Move files\n",
    "    shutil.copy(file, destination_directory)\n",
    "\n",
    "print(\"Files copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the files to simplify their name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Make counts of all variables listed in a folder, this process take time (more than 30 minutes) depends the size of the study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import geopandas as gpd\n",
    "\n",
    "# Path to the shapefile\n",
    "project_root = os.path.abspath(os.path.join(base_path, '../..'))\n",
    "\n",
    "shapefile_path = os.path.join(project_root, 'Grids', park, 'grid_wgs84_atrib/grid_wgs84_atrib.shp')\n",
    "# Read the shapefile using geopandas\n",
    "grid = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Path to the folder containing the GeoJSON files\n",
    "geojson_folder = os.path.join(project_root, '2_Derived metrics/count/Poligons uniques/', park)\n",
    "\n",
    "# List all files in the folder with .geojson extension\n",
    "geojson_files = [file for file in os.listdir(geojson_folder) if file.endswith('.geojson')]\n",
    "\n",
    "# Iterate over each GeoJSON file\n",
    "for geojson_file in geojson_files:\n",
    "    # Construct the full path of the GeoJSON file\n",
    "    geojson_path = os.path.join(geojson_folder, geojson_file)\n",
    "    \n",
    "    # Read the GeoJSON\n",
    "    with open(geojson_path, encoding='utf-8') as f:\n",
    "        point_data = json.load(f)\n",
    "    \n",
    "    # Convert the GeoJSON to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame.from_features(point_data['features'])\n",
    "    \n",
    "    if gdf.empty:\n",
    "        pass\n",
    "    else:\n",
    "        # Create a new column in the grid GeoDataFrame to store point counts\n",
    "        column_name = f'{geojson_file}'  # Use part of the file name as the column name f'{geojson_file[:-13]}'\n",
    "        grid[column_name] = 0\n",
    "\n",
    "        # Iterate over each grid cell\n",
    "        for idx, cell in grid.iterrows():\n",
    "            # Filter points that are within the current cell \n",
    "            # points_in_cell = gdf[gdf.geometry.within(cell['geometry'])]\n",
    "\n",
    "            points_in_cell = gdf[gdf.geometry.intersects(cell['geometry'])]\n",
    "\n",
    "            # Get the number of points in the cell and update the corresponding column\n",
    "            grid.at[idx, column_name] = len(points_in_cell)\n",
    "\n",
    "# Save the result to a new shapefile\n",
    "grid.to_file(os.path.join(project_root, '2_Derived metrics/count/results', park, 'grid_wgs84_atrib_count.shp'), driver='ESRI Shapefile')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproject the grid with the count values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf = gpd.read_file(f'C:/Users/carlo/Documents/EarthCul/OSM/2_Derived metrics/count/results/{park}/grid_wgs84_atrib_count.shp')\n",
    "gdf = gdf.to_crs('EPSG:3035')\n",
    "# Save the GeoDataFrame to a new GeoJSON file\n",
    "gdf.to_file(f'C:/Users/carlo/Documents/EarthCul/OSM/2_Derived metrics/count/results/{park}/grid_3035_count.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally rasterize the columns where from the grid with the values of the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "\n",
    "# Grid and base raster\n",
    "Grid = os.path.join(base_path, '2_Derived metrics/count/results', park, 'grid_3035_count.shp')\n",
    "\n",
    "Base_raster = os.path.join(base_path, '2_Derived metrics/BaseLayers', park, 'Slope.tif')\n",
    "              \n",
    "# Output folder\n",
    "output_folder = os.path.join(base_path, '2_Derived metrics/count/results', park)\n",
    "\n",
    "# Read the grid shapefile\n",
    "gdf = gpd.read_file(Grid)\n",
    "\n",
    "# Open the base raster to get its profile\n",
    "with rasterio.open(Base_raster) as src:\n",
    "    profile = src.profile  \n",
    "\n",
    "    # Loop through columns to rasterize \n",
    "    columns_to_process = gdf.columns.tolist()[3:]\n",
    "    for column in tqdm(columns_to_process, desc='Rasterizing Columns'):\n",
    "        values = gdf[column].values\n",
    "        \n",
    "        # Rasterize the values\n",
    "        rasterized = features.rasterize(\n",
    "            zip(gdf.geometry, values),\n",
    "            out_shape=(profile['height'], profile['width']),\n",
    "            transform=profile['transform'],\n",
    "            fill=-999.99,  \n",
    "            all_touched=True,  \n",
    "            default_value=0,  \n",
    "            dtype=profile['dtype']  \n",
    "        )\n",
    " \n",
    "        output_path = os.path.join(output_folder, f'{column}.tif')\n",
    "        \n",
    "        # Save the outputs\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            dst.write(rasterized, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

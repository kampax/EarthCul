{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join layers \n",
    "The idea is to unite the different layers that have things in common into one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "\n",
    "base_path = os.getcwd()\n",
    "#Lists of parks of interest\n",
    "#// Aiguestortes\n",
    "#// Ordesa\n",
    "#// Peneda\n",
    "#// Guadarrama\n",
    "#// Picos\n",
    "#// SierraNieves\n",
    "#// SierraNevada\n",
    "#// Teide\n",
    "parque = 'Aiguestortes'\n",
    "\n",
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/highway_motorway.geojson\"))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/highway_motorway_link.geojson\"))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/highway_trunk.geojson\"))\n",
    "gdf_4 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/highway_trunk_link.geojson\"))\n",
    "gdf_5 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/highway_primary.geojson\"))\n",
    "gdf_6 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/highway_secondary.geojson\"))\n",
    "gdf_7 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/highway_tertiary.geojson\"))\n",
    "gdf_8 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/highway_unclassified.geojson\"))\n",
    "# gdf_9 = gpd.read_file(\"C:/Users/carlo/Desktop/EarthCul OSM/Sierra Nevada/highway_trailhead_{parque}.geojson\")\n",
    "gdf_10 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/highway_track.geojson\"))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2,gdf_3, gdf_4, gdf_5, gdf_6,gdf_7, gdf_8, gdf_10], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/roads.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar and restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/amenity_bar.geojson\"))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/amenity_cafe.geojson\"))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/amenity_restaurant.geojson\"))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2,gdf_3], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/barAndRestaurant.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beaches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/natural_coastline.geojson\"))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/natural_beach.geojson\"))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/beaches.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bike routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/route_mtb.geojson\"))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/route_bicycle.geojson\"))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/bikeRoutes.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Campsite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/tourism_camp_site.geojson\"))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/tourism_caravan_site.geojson\"))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f\"EarthCul OSM/{parque}/tourism_camp_pitch.geojson\"))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/campsite.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\geopandas\\io\\file.py:612: UserWarning: You are attempting to write an empty DataFrame to file. For some drivers, this operation may fail.\n",
      "  _to_file_fiona(df, filename, driver, schema, crs, mode, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/geological_moraine.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/natural_moraine.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/natural_glacier.geojson'))\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/glacier.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Green spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/leisure_park.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/tourism_picnic_site.geojson'))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/greenSpaces.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/historic_monastery.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/amenity_monastery.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/historic_monument.geojson'))\n",
    "gdf_4 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/historic_memorial.geojson'))\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3, gdf_4], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/historic.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "c:\\Users\\carlo\\Documents\\Repositorio EarthCul\\EarthCul\\OSM\\1) Variable download\\EarthCul OSM/Aiguestortes/water_lake.geojson: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mfiona\\ogrext.pyx:136\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: c:\\Users\\carlo\\Documents\\Repositorio EarthCul\\EarthCul\\OSM\\1) Variable download\\EarthCul OSM/Aiguestortes/water_lake.geojson: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load GeoJSON files as GeoDataFrames\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m gdf_1 \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEarthCul OSM/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparque\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/water_lake.geojson\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      3\u001b[0m gdf_2 \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEarthCul OSM/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparque\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/water_lagoon.geojson\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m gdf_3 \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEarthCul OSM/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparque\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/water_oxbow.geojson\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\geopandas\\io\\file.py:297\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[1;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_fiona(\n\u001b[0;32m    298\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    299\u001b[0m     )\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\geopandas\\io\\file.py:338\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[1;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m reader(path_or_bytes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[0;32m    339\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[0;32m    340\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\fiona\\env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\fiona\\__init__.py:335\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 335\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    336\u001b[0m         path,\n\u001b[0;32m    337\u001b[0m         mode,\n\u001b[0;32m    338\u001b[0m         driver\u001b[38;5;241m=\u001b[39mdriver,\n\u001b[0;32m    339\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    340\u001b[0m         layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[0;32m    341\u001b[0m         enabled_drivers\u001b[38;5;241m=\u001b[39menabled_drivers,\n\u001b[0;32m    342\u001b[0m         allow_unsupported_drivers\u001b[38;5;241m=\u001b[39mallow_unsupported_drivers,\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    344\u001b[0m     )\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    346\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[0;32m    347\u001b[0m         path,\n\u001b[0;32m    348\u001b[0m         mode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    358\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\fiona\\collection.py:234\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[1;32mfiona\\ogrext.pyx:587\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mfiona\\ogrext.pyx:143\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDriverError\u001b[0m: c:\\Users\\carlo\\Documents\\Repositorio EarthCul\\EarthCul\\OSM\\1) Variable download\\EarthCul OSM/Aiguestortes/water_lake.geojson: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/water_lake.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/water_lagoon.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/water_oxbow.geojson'))\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/lakes.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/amenity_parking.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/amenity_bicycle_parking.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/amenity_motorcycle_parking.geojson'))\n",
    "# gdf_4 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/amenity_parking.geojson'))\n",
    "# gdf_5 = gpd.read_file(\"C:/Users/carlo/Desktop/EarthCul OSM/Sierra Nevada OSM/amenity_multi-storey_SierraNevada.geojson\")\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1,gdf_2, gdf_3], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/parking.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accommodation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/tourism_hostel.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/tourism_hotel.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/tourism_motel.geojson'))\n",
    "gdf_4 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/tourism_information.geojson'))\n",
    "gdf_5 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/leisure_resort.geojson'))\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3, gdf_4, gdf_5], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/accommodation.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/landuse_recreation_ground.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/leisure_playground.geojson'))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/recreational.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refuges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/shelter_type_basic_hut.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/amenity_shelter_type.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/tourism_alpine_hut.geojson'))\n",
    "gdf_4 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/tourism_wilderness_hut.geojson'))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3, gdf_4], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/refuges.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Religious Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/building_cathedral.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/building_chapel.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/building_church.geojson'))\n",
    "gdf_4 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/building_kingdom_hall.geojson'))\n",
    "gdf_5 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/building_monastery.geojson'))\n",
    "gdf_6 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/building_mosque.geojson'))\n",
    "gdf_7 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/building_presbytery.geojson'))\n",
    "gdf_8 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/building_religious.geojson'))\n",
    "gdf_9 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/building_synagogue.geojson'))\n",
    "gdf_10 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/amenity_place_of_worship.geojson'))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2,gdf_3, gdf_4, gdf_5, gdf_6,gdf_7, gdf_8, gdf_9, gdf_10], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/religious.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rivers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/waterway_river.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/waterway_riverbank.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/water_river.geojson'))\n",
    "gdf_4 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/water_stream.geojson'))\n",
    "gdf_5 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/waterway_stream.geojson'))\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3, gdf_4, gdf_5], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/rivers.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sighting points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/natural_peak.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/natural_ridge.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/natural_arete.geojson'))\n",
    "gdf_4 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/natural_cliff.geojson'))\n",
    "gdf_5 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/tourism_viewpoint.geojson'))\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3, gdf_4, gdf_5], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/sighting_points.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ski Facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/route_ski.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/route_piste.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/amenity_ski_rental.geojson'))\n",
    "gdf_4 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/aerialway_chair_lift.geojson'))\n",
    "gdf_5 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/aerialway_drag_lift.geojson'))\n",
    "gdf_6 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/landuse_winter_sports.geojson'))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3, gdf_4, gdf_5, gdf_6], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/ski_facilities.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/place_town.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/place_hamlet.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/place_isolated_dwelling.geojson'))\n",
    "gdf_4 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/place_village.geojson'))\n",
    "# gdf_5 = gpd.read_file(\"C:/Users/carlo/Desktop/EarthCul OSM/Sierra Nevada/place_neighbourhood_SierraNevada.geojson\")# Se lo excluye porque son sitios de nombres de lugares sin poblacion\n",
    "#gdf_6 = gpd.read_file(\"C:/Users/carlo/Desktop/EarthCul OSM/Sierra Nevada/place_locality_SierraNevada.geojson\")# Se lo excluye porque son sitios de nombres de lugares sin poblacion\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3, gdf_4], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/small_town.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/highway_living_street.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/highway_service.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/highway_residential.geojson'))\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([ gdf_1, gdf_2, gdf_3], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/streets.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tourism atraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/tourism_attraction.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/tourism_museum.geojson'))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/tourismAttraction.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "volcanic topography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\geopandas\\io\\file.py:612: UserWarning: You are attempting to write an empty DataFrame to file. For some drivers, this operation may fail.\n",
      "  _to_file_fiona(df, filename, driver, schema, crs, mode, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/natural_volcano.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/geological_volcanic_caldera_rim.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/geological_volcanic_lava_field.geojson'))\n",
    "gdf_4 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/geological_volcanic_vent.geojson'))\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3, gdf_4], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/volcanic.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Water bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load GeoJSON files as GeoDataFrames\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/natural_water.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/landuse_reservoir.geojson'))\n",
    "gdf_3 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/landuse_basin.geojson'))\n",
    "gdf_4 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/water_reservoir.geojson'))\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([gdf_1, gdf_2, gdf_3, gdf_4], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/waterBodies.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WIFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "#gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque} OSM/wifi_None_{parque}.geojson'))\n",
    "gdf_2 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/internet_access_wlan.geojson'))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([ gdf_2], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/wifi.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Courts, cambia el nombre de pitch a Courts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON files as GeoDataFrames\n",
    "\n",
    "gdf_1 = gpd.read_file(os.path.join(base_path, f'EarthCul OSM/{parque}/leisure_pitch.geojson'))\n",
    "\n",
    "# Combine the GeoDataFrames into one\n",
    "gdf_combinado = pd.concat([ gdf_1], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame to a GeoDataFrame\n",
    "gdf_combinado = gpd.GeoDataFrame(gdf_combinado, geometry='geometry')\n",
    "\n",
    "# Save the combined GeoDataFrame to a new GeoJSON file\n",
    "gdf_combinado.to_file(os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables/leisure_court.geojson'), driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mover archivos no unidos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos movidos con éxito.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# Source and destination directory\n",
    "directorio_origen = os.path.join(base_path, f'EarthCul OSM/{parque}')\n",
    "directorio_destino = os.path.join(base_path, f'EarthCul OSM/{parque}/definitive variables')\n",
    "\n",
    "\n",
    "# Terms you want to search for in file names\n",
    "terminos = [\"bicycle_rental\", \"bus_stop\", \"climbing\", \"drinking_water\", \"fountain\",\n",
    "            \"hiking\", \"railway_rail\", \"social_facility\", \"square\", \"community_centre\", \"palaeontological_site\"]\n",
    "\n",
    "# Create the destination directory if it does not exist\n",
    "if not os.path.exists(directorio_destino):\n",
    "    os.makedirs(directorio_destino)\n",
    "\n",
    "# Get the list of files in the source directory\n",
    "archivos_en_origen = glob.glob(os.path.join(directorio_origen, \"*.geojson\"))\n",
    "\n",
    "# Filter files based on terms\n",
    "archivos_a_mover = [archivo for archivo in archivos_en_origen if any(termino in os.path.basename(archivo) for termino in terminos)]\n",
    "\n",
    "# Move the leaked files to the destination directory\n",
    "for archivo in archivos_a_mover:\n",
    "    shutil.move(archivo, directorio_destino)\n",
    "\n",
    "print(\"Archivos movidos con éxito.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
